# =============================================================================
# LLM Provider Configuration
# =============================================================================

# Choose your LLM provider: "glm" or "gemini"
LLM_PROVIDER=glm

# Temperature for LLM (0 = deterministic, 1 = creative)
TEMPERATURE=0

# Enable multimodal features (image understanding)
# Requires Gemini or GLM-4V
ENABLE_MULTIMODAL=false

# Multimodal Configuration (for image understanding)
# Maximum number of images to send per API request (to avoid timeout)
MAX_IMAGES_PER_REQUEST=5
# Maximum image dimension in pixels (larger images will be resized)
MAX_IMAGE_SIZE=1024
# Request timeout in seconds for multimodal requests
REQUEST_TIMEOUT=300

# =============================================================================
# GLM API Configuration (智谱AI)
# Get your API key from: https://open.bigmodel.cn/
# =============================================================================
GLM_API_KEY=your_glm_api_key_here
GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
GLM_MODEL=GLM-4.6

# =============================================================================
# Gemini API Configuration (Google)
# Get your API key from: https://aistudio.google.com/apikey
# =============================================================================
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp

# Available Gemini models:
# - gemini-2.0-flash-exp (recommended, fast and efficient)
# - gemini-1.5-flash (stable, good for production)
# - gemini-1.5-pro (most capable, slower)

# =============================================================================
# Logging Configuration
# =============================================================================
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
